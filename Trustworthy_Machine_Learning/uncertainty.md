## Topic: Uncertainty Quantification

A compiled list of papers on uncertainty quantification.

Last updated: 29 July 2024

### Icon description:

ğŸ¥‡ at least 1k citations (at the time of reading)

ğŸ¥ˆ at least 500 citations (at the time of reading)

ğŸ¥‰ at least 50 citations (at the time of reading)

ğŸ’¥ less than 50 citations (at the time of reading)

ğŸ† Highly Recommended: Read in detail and found very interesting.

ğŸ“š Reviewed: Read in detail.

ğŸ“ Skimmed: Read briefly.

ğŸ“… To Be Read (TBR): Plan to read.

----

### Table of Contents:
- [Survey/Intro](#surveyintro)
- [Confidence Calibration](#confidence-calibration)
- [Misclassification Detection](#misclassification-detection)
- [Selective Prediction](#selective-prediction)
- [Bayesian Approaches](#bayesian-approaches)
- [Ensembling Approaches](#ensembling-approaches)
- [Others](#others)

----

### Survey/Intro

* ğŸ’¥ğŸ“ 2023: [A Survey on Uncertainty Quantification Methods for Deep Learning](https://arxiv.org/pdf/2302.13425) <br>

* ğŸ¥ˆğŸ“… 2023: [A Survey of Uncertainty in Deep Neural Networks](https://arxiv.org/pdf/2107.03342) <br>

* ğŸ¥‰ğŸ“… 2022: [A Survey on Uncertainty Estimation in Deep Learning Classification Systems from a Bayesian Perspective](https://diposit.ub.edu/dspace/bitstream/2445/183476/1/714838.pdf) <br>

* ğŸ¥‡ğŸ“… 2021: [Aleatoric and Epistemic Uncertainty in Machine Learning: An Introduction to Concepts and Methods](https://arxiv.org/pdf/1910.09457)

### Confidence Calibration

* ğŸ’¥ğŸ“ 2024: [A Benchmark Study on Calibration](https://arxiv.org/pdf/2308.11838)

* ğŸ’¥ğŸ“ 2024: [Smooth ECE: Principled reliability diagrams via kernel smoothing](https://arxiv.org/pdf/2309.12236) ([Code](https://github.com/apple/ml-calibration))

* ğŸ¥‰ğŸ“ 2021: [Rethinking Calibration of Deep Neural Networks: Do Not Be Afraid of Overconfidence](https://proceedings.neurips.cc/paper_files/paper/2021/file/61f3a6dbc9120ea78ef75544826c814e-Paper.pdf) <br>

* ğŸ¥‰ğŸ“ 2019: [Measuring Calibration in Deep Learning](https://arxiv.org/pdf/1904.01685) <br> 

* ğŸ¥‡ğŸ† 2017: [On Calibration of Modern Neural Networks](https://arxiv.org/pdf/1706.04599) <br>

### Misclassification Detection

* ğŸ’¥ğŸ“ 2023: [A Call to Reflect on Evaluation Practices for Failure Detection in Image Classification](https://arxiv.org/pdf/2211.15259) ([Code](https://github.com/IML-DKFZ/fd-shifts)) <br>

* ğŸ’¥ğŸ“ 2023: [Rethinking Confidence Calibration for Failure Prediction](https://arxiv.org/pdf/2303.02970) ([Code](https://github.com/Impression2805/FMFP)) <br>

* ğŸ¥‰ğŸ“ 2019: [Addressing Failure Prediction by Learning Model Confidence](https://arxiv.org/pdf/1910.04851) ([Code](https://github.com/valeoai/ConfidNet)) <br>

* ğŸ¥ˆğŸ“ 2018 : [To Trust Or Not To Trust A Classifier](https://arxiv.org/pdf/1805.11783) <br>

* ğŸ¥‡ğŸ“ 2017: [A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks](https://arxiv.org/pdf/1610.02136) <br>

### Out-of-distribution Detection

* ğŸ¥‡ğŸ“… 2018: [Enhancing The Reliability of Out-of-distribution Image Detection in Neural Networks](https://arxiv.org/pdf/1706.02690)<br>

* ğŸ¥ˆğŸ“… 2018: [Learning Confidence for Out-of-Distribution Detection in Neural Networks](https://arxiv.org/pdf/1802.04865) ([Code](https://github.com/uoguelph-mlrg/confidence_estimation)) <br>

* ğŸ¥‡ğŸ“ 2017: [A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks](https://arxiv.org/pdf/1610.02136) <br>

### Selective Prediction

* ğŸ’¥ğŸ“… 2024: [Calibrated Selective Classification](https://arxiv.org/pdf/2208.12084) <br>

* ğŸ’¥ğŸ“… 2023: [What Can We Learn From The Selective Prediction And Uncertainty Estimation Performance Of 523 Imagenet Classifiers?](https://arxiv.org/pdf/2302.11874) <br>

* ğŸ’¥ğŸ“… 2023: [Towards Better Selective Classification](https://arxiv.org/pdf/2206.09034) ([Code](https://github.com/LayneH/SAT-selective-cls)) <br>

* ğŸ¥‰ğŸ“… 2019: [SelectiveNet: A Deep Neural Network with an Integrated Reject Option](https://arxiv.org/pdf/1901.09192) <br>

* ğŸ¥ˆğŸ“ 2017: [Selective Classification for Deep Neural Networks](https://arxiv.org/pdf/1705.08500) <br>

### Bayesian Approaches

* ğŸ¥‡ğŸ“… 2017: [What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision?](https://arxiv.org/pdf/1703.04977) <br>

* ğŸ¥‡ğŸ“… 2016: [Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning](https://arxiv.org/pdf/1506.02142) <br>

* ğŸ¥‡ğŸ“… 2016: [Uncertainty in Deep Learning](https://www.cs.ox.ac.uk/people/yarin.gal/website/thesis/thesis.pdf) <br>
This is Yarin Gal's thesis which compiles his work on obtaining uncertainty estimates using Bayesian approach.

### Ensembling Approaches

* ğŸ¥‰ğŸ“… 2018: [High-Quality Prediction Intervals for Deep Learning: A Distribution-Free, Ensembled Approach](https://arxiv.org/pdf/1802.07167) <br>

* ğŸ¥‡ğŸ“… 2017: [Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles](https://arxiv.org/pdf/1612.01474) <br>

### Others

* ğŸ’¥ğŸ“… 2023: [Confidence Estimation via Auxiliary Models](https://arxiv.org/pdf/2012.06508) <br>

* ğŸ¥‰ğŸ“… 2022: [Mitigating Neural Network Overconfidence with Logit Normalization](https://arxiv.org/pdf/2205.09310) <br>

* ğŸ¥‰ğŸ“… 2020: [Confidence-Aware Learning for Deep Neural Networks](https://arxiv.org/pdf/2007.01458) <br>
